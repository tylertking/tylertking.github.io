---
layout: default
title: Detecting AI Assistance in Abstract Complex Tasks

research: active
projects: passive

description: Detecting AI Assistance in Abstract Complex Tasks
---
<div class="text-center">
	<h1>{{page.description}}</h1>

	<img class="img-fluid" src="/img/complex_task_classification_pipeline.pdf" height="200">
	<br>
	<br>

	<center><hr width="75%"></center>

	<p><b>Abstract:</b> Detecting assistance from artificial intelligence is increasingly important as they become ubiquitous across complex tasks such as text generation, medical diagnosis, and autonomous driving. Aid detection is challenging for humans, especially when looking at abstract task data. Artificial neural networks excel at classification thanks to their ability to quickly learn from and process large amounts of data -- assuming appropriate preprocessing. We posit detecting help from AI as a classification task for such models. Much of the research in this space examines the classification of complex but concrete data classes, such as images. Many AI assistance detection scenarios, however, result in data that is not machine learning-friendly. We demonstrate that common models can effectively classify such data when it is appropriately preprocessed. To do so, we construct four distinct neural network-friendly image formulations along with an additional time-series formulation that explicitly encodes the exploration/exploitation of users, which allows for generalizability to other abstract tasks. We benchmark the quality of each image formulation across three classical deep learning architectures, along with a parallel CNN-RNN architecture that leverages the additional time series to maximize testing performance, showcasing the importance of encoding temporal and spatial quantities for detecting AI aid in abstract tasks.  </p>

	<h4>Paper: <a href="https://arxiv.org/abs/2507.10761">Detecting AI Assistance in Abstract Complex Tasks</a></h4>
	
	
	<p>Proceedings to be published in CCIS. </p>
	<p><a href="https://2025.hci.international/">Poster presented in HCII, 2025.</a> </p>


	<center><hr width="50%"></center>

</div>